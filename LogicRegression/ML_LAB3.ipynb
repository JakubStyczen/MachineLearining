{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regresja logistyczna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import math\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def h_fun(X, theta):\n",
    "    z = theta.T @ X\n",
    "    h = 1.0 / (1.0 + np.exp(-z))\n",
    "    return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_cost(X, y, theta):\n",
    "    h = h_fun(X, theta)\n",
    "    y_1 = -y*np.log(h)\n",
    "    y_0 = -(1-y)*np.log(1-h)\n",
    "    return (y_1 + y_0).sum() / X.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0],\n",
    "              [0.3, 0.8, 1.7, 2.4, 2.9, 3.1, 4.5, 6.1]])\n",
    "y = np.array([[0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0]])\n",
    "\n",
    "eps = 1e-5  # akceptowalna różnica dla kolejnych wartości funkcji kosztu \n",
    "alpha = 0.001  # learning rate\n",
    "theta_0 = 0  # - wartości początkowe parametrów modelu\n",
    "theta_1 = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent_ndim(X, y, theta, alpha=alpha, eps=eps, max_iter=100000):\n",
    "    '''\n",
    "    :param X: ndarray o wymiarze ilości przykładów\n",
    "    :param y: ndarray z wartościami referencyjnymi o wymiarze takim jak x\n",
    "    :param theta: początkowy parametr modelu regresji liniowej jednej zmiennej\n",
    "    :param alpha: współczynnik uczenia (learning rate)\n",
    "    :param eps: tolerancja zmiany kosztu, aby zakończyć iterację\n",
    "    :return: theta- optymalne parametry modelu regresji liniowej\n",
    "    '''\n",
    "    m = X.shape[0]\n",
    "    cost_history = [] \n",
    "\n",
    "    for i in range(max_iter):\n",
    "        h_y_diff = (h_fun(X, theta) - y)\n",
    "        gradient = h_y_diff @ X.T\n",
    "        theta = theta - alpha * gradient.T / m\n",
    "        \n",
    "        cost = calculate_cost(X, y, theta)\n",
    "        cost_history.append(cost)\n",
    "\n",
    "        if i > 0 and abs(cost - cost_history[i-1]) < eps:\n",
    "            break\n",
    "\n",
    "    return theta, h_fun(X, theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
